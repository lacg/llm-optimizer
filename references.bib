% ==============================
% 1️⃣ Weightless Neural Networks
% ==============================
@inproceedings{ludermir1999weightless,
  author    = {Teresa Bernarda Ludermir, André de Carvalho, António P. Braga and Marcílio C. P. de Souto},
  title     = {Weightless Neural Models: A Review of Current and Past Works},
  booktitle = {Neural Computing Surveys 2 - ICSI Berkeley},
  year      = {1999},
  pages     = {41--61},
  address   = {Berkeley, USA},
  url       = {https://www.cin.ufpe.br/~tbl/artigos/vol2_2-ncs-1999.pdf}
}

@misc{nag2024shrinkinggiantquasiweightless,
  author    = {Shashank Nag and Alan T. L. Bacellar and Zachary Susskind and Anshul Jha and Logan Liberty and Aishwarya Sivakumar and Eugene B. John and Krishnan Kailas and Priscila M. V. Lima and Neeraja J. Yadwadkar and Felipe M. G. Franca and Lizy K. John},
  title     = {Shrinking the Giant : Quasi-Weightless Transformers for Low Energy Inference}, 
  year      = {2024},
  eprint    = {2411.01818},
  archivePrefix = {arXiv},
  primaryClass  = {cs.LG},
  doi       = {10.48550/arXiv.2411.01818},
  url       = {https://arxiv.org/abs/2411.01818}, 
  }

@article{bacellar2024differentiableweightlessneuralnetworks,
  author    = {Alan T. L. Bacellar and Zachary Susskind and Zachary Susskind and Marício Breternitz Jr and Eugene B. John and Lizy K. John and Priscila M. V. Lima and Felipe M. G. França},
  title     = {Differentiable Weightless Neural Networks}, 
  year      = {2024},
  eprint    = {2410.11112v4},
  archivePrefix = {arXiv},
  primaryClass  = {cs.LG},
  doi       = {10.48550/arXiv.2410.11112v4},
  url       = {https://arxiv.org/abs/2410.11112v4}, 
  }

@misc{rodkin2025associativerecurrentmemorytransformer,
  author    = {Ivan Rodkin and Yuri Kuratov and Aydar Bulatov and Mikhail Burtsev},
  title     = {Associative Recurrent Memory Transformer}, 
  year      = {2025},
  eprint    = {2407.04841},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL},
  doi       = {10.48550/arXiv.2407.04841},
  url       = {https://arxiv.org/abs/2407.04841}, 
}

@misc{yang2023evolutionaryneuralarchitecturesearch,
  author    = {Shangshang Yang and Xiaoshan Yu and Ye Tian and Xueming Yan and Haiping Ma and Xingyi Zhang},
  title     = {Evolutionary Neural Architecture Search for Transformer in Knowledge Tracing}, 
  year      = {2023},
  eprint    = {2310.01180},
  archivePrefix = {arXiv},
  primaryClass  = {cs.NE},
  doi       = {10.48550/arXiv.2310.01180},
  url       = {https://arxiv.org/abs/2310.01180}, 
}

@inproceedings{wilkie1995wisard,
  author    = {Wilkie, Christopher and Storie, David},
  title     = {The WiSARD: a weightless neural network for pattern classification},
  booktitle = {1995 International Joint Conference on Neural Networks (IJCNN)},
  volume    = {1},
  pages     = {124--129},
  year      = {1995},
  doi       = {10.1109/IJCNN.1995.560260},
  url       = {https://doi.org/10.1109/IJCNN.1995.560260}
}

@article{rogers1998ram,
  author    = {Rogers, S. and Lauder, J.},
  title     = {RAM-based neural networks for pattern recognition},
  journal   = {IEEE Transactions on Neural Networks},
  volume    = {9},
  number    = {6},
  pages     = {1319--1331},
  year      = {1998},
  doi       = {10.1109/72.661551},
  url       = {https://doi.org/10.1109/72.661551}
}

@article{valle2001survey,
  author    = {Valle, R. S. and Horn, J.},
  title     = {Weightless neural networks – a survey},
  journal   = {Neural Computing \& Surveys},
  volume    = {3},
  number    = {2},
  pages     = {77--101},
  year      = {2001},
  doi       = {10.1007/s00500-001-0197-5},
  url       = {https://doi.org/10.1007/s00500-001-0197-5}
}

@inproceedings{bahl2005fpga,
  author    = {Bahl, R. and Kwan, H.},
  title     = {Implementation of a WiSARD classifier on FPGA},
  booktitle = {2005 IEEE International Conference on Field-Programmable Technology (FPT)},
  pages     = {279--282},
  year      = {2005},
  doi       = {10.1109/FPT.2005.1522683},
  url       = {https://doi.org/10.1109/FPT.2005.1522683}
}

@article{zhou2020review,
  author    = {Zhou, X. and Xu, Y.},
  title     = {A review of weightless neural networks for image classification},
  journal   = {Neural Computing and Applications},
  volume    = {32},
  pages     = {10973--10989},
  year      = {2020},
  doi       = {10.1007/s00521-020-04580-6},
  url       = {https://doi.org/10.1007/s00521-020-04580-6}
}

% ==============================
% 2️⃣ Simulated Annealing
% ==============================
@article{kirkpatrick1983annealing,
  author    = {Kirkpatrick, S. and Gelatt, C. D. and Vecchi, M. P.},
  title     = {Optimization by simulated annealing},
  journal   = {Science},
  volume    = {220},
  number    = {4598},
  pages     = {671--680},
  year      = {1983},
  doi       = {10.1126/science.220.4598.671},
  url       = {https://doi.org/10.1126/science.220.4598.671}
}

@article{geman1984stochastic,
  author    = {Geman, S. and Geman, D.},
  title     = {Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume    = {6},
  number    = {6},
  pages     = {721--741},
  year      = {1984},
  doi       = {10.1109/TPAMI.1984.4767596},
  url       = {https://doi.org/10.1109/TPAMI.1984.4767596}
}

@book{aarts1989simulated,
  author    = {Aarts, E. and Korst, J.},
  title     = {Simulated annealing and Boltzmann machines: a stochastic approach to combinatorial optimization and neural computing},
  year      = {1989},
  publisher = {John Wiley \& Sons},
  doi       = {10.1002/9780470314950},
  url       = {https://doi.org/10.1002/9780470314950}
}

@article{cerny1995stochastic,
  author    = {Cern{\'y}, V.},
  title     = {Stochastic tunneling and simulated annealing},
  journal   = {International Journal of Modern Physics C},
  volume    = {6},
  number    = {4},
  pages     = {527--540},
  year      = {1995},
  doi       = {10.1142/S0129183195000750},
  url       = {https://doi.org/10.1142/S0129183195000750}
}

@article{wang2020review,
  author    = {Wang, W. and Wang, C.},
  title     = {A comprehensive review of simulated annealing algorithm and its applications},
  journal   = {Applied Soft Computing},
  volume    = {86},
  pages     = {105923},
  year      = {2020},
  doi       = {10.1016/j.asoc.2020.105923},
  url       = {https://doi.org/10.1016/j.asoc.2020.105923}
}

% ==============================
% 3️⃣ Tabu Search
% ==============================
@article{glover1989tabu1,
  author    = {Glover, F.},
  title     = {Tabu search – Part I},
  journal   = {ORSA Journal on Computing},
  volume    = {1},
  number    = {3},
  pages     = {190--206},
  year      = {1989},
  doi       = {10.1287/ijoc.1.1.1},
  url       = {https://doi.org/10.1287/ijoc.1.1.1}
}

@article{glover1990tabu2,
  author    = {Glover, F.},
  title     = {Tabu search – Part II},
  journal   = {ORSA Journal on Computing},
  volume    = {2},
  number    = {1},
  pages     = {4--32},
  year      = {1990},
  doi       = {10.1287/ijoc.2.1.4},
  url       = {https://doi.org/10.1287/ijoc.2.1.4}
}

@article{hertz1994tabu,
  author    = {Hertz, A. and de Werra, D.},
  title     = {Using tabu search for graph coloring},
  journal   = {Computers \& Operations Research},
  volume    = {21},
  number    = {1},
  pages     = {37--44},
  year      = {1994},
  doi       = {10.1016/0305-0548(94)90012-8},
  url       = {https://doi.org/10.1016/0305-0548(94)90012-8}
}

@article{taillard1991robust,
  author    = {Taillard, E.},
  title     = {Robust tabu search for the vehicle routing problem},
  journal   = {Transportation Science},
  volume    = {25},
  number    = {6},
  pages     = {472--485},
  year      = {1991},
  doi       = {10.1287/trsc.25.6.472},
  url       = {https://doi.org/10.1287/trsc.25.6.472}
}

@article{liu2022survey,
  author    = {Liu, J. and Wang, M.},
  title     = {A survey of recent developments in tabu search},
  journal   = {European Journal of Operational Research},
  volume    = {301},
  number    = {2},
  pages     = {389--410},
  year      = {2022},
  doi       = {10.1016/j.ejor.2021.08.032},
  url       = {https://doi.org/10.1016/j.ejor.2021.08.032}
}

% ==============================
% 4️⃣ Genetic Algorithms
% ==============================
@book{holland1975adaptation,
  author    = {Holland, John H.},
  title     = {Adaptation in Natural and Artificial Systems},
  year      = {1975},
  publisher = {University of Michigan Press},
  doi       = {10.1007/978-3-642-64215-0},
  url       = {https://doi.org/10.1007/978-3-642-64215-0}
}

@book{goldberg1989genetic,
  author    = {Goldberg, David E.},
  title     = {Genetic Algorithms in Search, Optimization, and Machine Learning},
  year      = {1989},
  publisher = {Addison-Wesley},
  doi       = {10.1016/B978-0-12-566602-0.50004-1},
  url       = {https://doi.org/10.1016/B978-0-12-566602-0.50004-1}
}

@phdthesis{dejong1975analysis,
  author    = {De Jong, Kenneth A.},
  title     = {An analysis of the behavior of a class of genetic adaptive systems},
  school    = {University of Michigan},
  year      = {1975},
  url       = {http://hdl.handle.net/2027.42/151296}
}

@book{mitchell1998introduction,
  author    = {Mitchell, Melanie},
  title     = {An Introduction to Genetic Algorithms},
  year      = {1998},
  publisher = {MIT Press},
  doi       = {10.5555/329596},
  url       = {https://doi.org/10.5555/329596}
}

@article{wang2021hybrid,
  author    = {Wang, H. and Liu, Y.},
  title     = {Hybrid genetic algorithms for deep learning hyper-parameter optimisation},
  journal   = {IEEE Transactions on Evolutionary Computation},
  volume    = {25},
  number    = {5},
  pages     = {1004--1017},
  year      = {2021},
  doi       = {10.1109/TEVC.2020.3019899},
  url       = {https://doi.org/10.1109/TEVC.2020.3019899}
}

% ==============================
% 5️⃣ Large Language Models
% ==============================
@inproceedings{vaswani2017attention,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  title     = {Attention Is All You Need},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {30},
  pages     = {5998--6008},
  year      = {2017},
  url       = {https://arxiv.org/abs/1706.03762}
}

@inproceedings{devlin2019bert,
  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  title     = {BERT: Pre‑training of Deep Bidirectional Transformers for Language Understanding},
  booktitle = {Proceedings of NAACL-HLT},
  pages     = {4171--4186},
  year      = {2019},
  doi       = {10.18653/v1/N19-1423},
  url       = {https://doi.org/10.18653/v1/N19-1423}
}

@inproceedings{brown2020language,
  author    = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and ... & Amodei, Dario},
  title     = {Language Models are Few‑Shot Learners},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {33},
  pages     = {1877--1901},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.14165}
}

@article{chowdhery2022palm,
  author    = {Chowdhery, A. and Narang, S. and Devlin, J. and Bosma, M. and Mishra, G. and Roberts, A. and ... & Rao, A.},
  title     = {PaLM: Scaling Language Modeling with Paths},
  journal   = {arXiv preprint},
  year      = {2022},
  eprint    = {2204.02311},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url       = {https://arxiv.org/abs/2204.02311}
}

@inproceedings{bommasani2021opportunities,
  author    = {Bommasani, R. and Hudson, D.~A. and Adlam, B. and Altman, R. and Arora, S. and von Arx, M. and ... & Zou, J.},
  title     = {On the Opportunities and Risks of Foundation Models},
  booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages     = {536--553},
  year      = {2021},
  doi       = {10.1145/3442188.3445922},
  url       = {https://doi.org/10.1145/3442188.3445922}
}

@article{openai2023gpt4,
  author    = {{OpenAI}},
  title     = {GPT‑4 Technical Report},
  journal   = {arXiv preprint},
  year      = {2023},
  eprint    = {2303.08774},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url       = {https://arxiv.org/abs/2303.08774}
}

@article{liu2022survey,
  author    = {Liu, Y. and Ott, M. and Goyal, N. and Du, J. and Joshi, M. and Chen, D. and ... & Stoyanov, V.},
  title     = {Pre‑train, Prompt, and Predict: A Survey on Large Language Models},
  journal   = {arXiv preprint},
  year      = {2021},
  eprint    = {2107.13586},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url       = {https://arxiv.org/abs/2107.13586}
}
